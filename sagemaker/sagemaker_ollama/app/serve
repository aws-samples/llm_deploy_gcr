#!/bin/bash

# 检查 OLLAMA_MODEL_ID 环境变量
if [ -z "$OLLAMA_MODEL_ID" ]; then
    echo "WARNING: OLLAMA_MODEL_ID environment variable is not set!"
    echo "Please set OLLAMA_MODEL_ID to specify which model to load."
    exit 1
fi

echo "Starting Ollama service with model: $OLLAMA_MODEL_ID"

source /app/.venv/bin/activate

export OLLAMA_HOST="0.0.0.0:8000"
export OLLAMA_KEEP_ALIVE=${OLLAMA_KEEP_ALIVE:"-1"}
export OLLAMA_NUM_PARALLEL=${OLLAMA_NUM_PARALLEL:-"4"}

echo "Starting Ollama server on $OLLAMA_HOST..."
/usr/bin/ollama serve &

echo "Waiting for Ollama server to start..."
sleep 3

echo "Pulling model: $OLLAMA_MODEL_ID"
/usr/bin/ollama pull ${OLLAMA_MODEL_ID}

if [ $? -eq 0 ]; then
    echo "Model $OLLAMA_MODEL_ID pulled successfully"
else
    echo "ERROR: Failed to pull model $OLLAMA_MODEL_ID"
    exit 1
fi

echo "Starting FastAPI proxy server..."
python3 /app/run_server.py