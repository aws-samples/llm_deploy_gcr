{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71a329f0",
   "metadata": {},
   "source": [
    "# LMI vLLM DeepSeek-R1-Distill-Llama-70B vLLM deployment guide\n",
    "\n",
    "In this tutorial, you will use LMI container from DLC to SageMaker and run inference with it.\n",
    "\n",
    "Please make sure the following permission granted before running the notebook:\n",
    "\n",
    "- S3 bucket push access\n",
    "- SageMaker access\n",
    "\n",
    "## Step 1: Let's bump up SageMaker and import stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fa3208",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install -U sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9ac353",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import Model, image_uris, serializers, deserializers\n",
    "\n",
    "role = sagemaker.get_execution_role()  # execution role for the endpoint\n",
    "sess = sagemaker.session.Session()  # sagemaker session for interacting with different AWS APIs\n",
    "region = sess._region_name  # region name of the current SageMaker Studio environment\n",
    "account_id = sess.account_id()  # account_id of the current SageMaker Studio environment\n",
    "sagemaker_default_bucket = sess.default_bucket()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81deac79",
   "metadata": {},
   "source": [
    "## Step 2: Start preparing model artifacts\n",
    "In LMI contianer, we expect some artifacts to help setting up the model\n",
    "- serving.properties (required): Defines the model server settings\n",
    "- model.py (optional): A python file to define the core inference logic\n",
    "- requirements.txt (optional): Any additional pip wheel need to install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31831062-6df7-42f5-9069-b52408695c62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name=\"deepseek-ai/DeepSeek-R1-Distill-Llama-70B\"\n",
    "\n",
    "model_lineage=model_name.split(\"/\")[0]\n",
    "model_specific_name = model_name.split(\"/\")[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d85d2de-c7bf-48f8-b3e8-b71481f4091d",
   "metadata": {},
   "source": [
    "### Download model and upload to S3\n",
    "\n",
    "1. Download model from Hugging face\n",
    "2. Upload model to S3 Bucket\n",
    "3. Write serving.properties using s3url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58eba4e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -U huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fbcec8-d3b2-48d7-967b-0439760e83c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Uncomment this for China Region\n",
    "# os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92d4461-407d-4984-9e45-eb5be0c5b736",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "local_model_path_name = model_name.split(\"/\")[-1]\n",
    "local_model_path = Path(local_model_path_name)\n",
    "local_model_path.mkdir(exist_ok=True)\n",
    "\n",
    "s3_model_prefix = f\"lmi/{local_model_path_name}\"\n",
    "s3url=f\"s3://{sagemaker_default_bucket}/{s3_model_prefix}\"\n",
    "print(s3url)\n",
    "print(f\"huggingface-cli download --resume-download {model_name} --local-dir {local_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d9e24c-c09f-478b-ae12-6c3b79b7df16",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!huggingface-cli download --resume-download {model_name} --local-dir {local_model_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240e33b9-3af3-4232-b4b4-692b515d0a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload model to S3\n",
    "print(f\"!aws s3 cp {local_model_path} {s3url} --recursive\")\n",
    "!aws s3 cp {local_model_path} {s3url} --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7887f5b6-95e8-4e90-9c2c-3df19438fb0f",
   "metadata": {},
   "source": [
    "### Compress model artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d917099-af28-491a-945d-edc71cec1858",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"serving.properties\", \"w\") as wf:\n",
    "    wf.write(f\"\"\"\n",
    "engine=Python\n",
    "option.model_id={s3url}\n",
    "option.enforce_eager=true\n",
    "option.tensor_parallel_degree=8\n",
    "option.rolling_batch=vllm\n",
    "option.max_model_len=12200\n",
    "option.max_rolling_batch_size=8\n",
    "option.gpu_memory_utilization=0.9\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0142973",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "mkdir mymodel\n",
    "mv serving.properties mymodel/\n",
    "tar czvf mymodel.tar.gz mymodel/\n",
    "rm -rf mymodel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e58cf33",
   "metadata": {},
   "source": [
    "## Step 3: Start building SageMaker endpoint\n",
    "In this step, we will build SageMaker endpoint from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d955679",
   "metadata": {},
   "source": [
    "### Getting the container image URI\n",
    "\n",
    "For more versions or regions, you should checkout [Large Model Inference available DLC](https://github.com/aws/deep-learning-containers/blob/master/available_images.md#large-model-inference-containers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a174b36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_uri = \"763104351884.dkr.ecr.us-west-2.amazonaws.com/djl-inference:0.33.0-lmi15.0.0-cu128\"\n",
    "\n",
    "# for China (Beijing) cn-north-1\n",
    "# image_uri = \"727897471807.dkr.ecr.cn-north-1.amazonaws.com.cn/djl-inference:0.33.0-lmi15.0.0-cu128\"\n",
    "\n",
    "# for China (Ningxia) cn-northwest-1\n",
    "# image_uri = \"727897471807.dkr.ecr.cn-northwest-1.amazonaws.com.cn/djl-inference:0.33.0-lmi15.0.0-cu128\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11601839",
   "metadata": {},
   "source": [
    "### Upload artifact on S3 and create SageMaker model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b1e5ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_code_prefix = f\"large-model-lmi/code-{model_lineage}-{model_specific_name}\"\n",
    "bucket = sess.default_bucket()  # bucket to house artifacts\n",
    "code_artifact = sess.upload_data(\"mymodel.tar.gz\", bucket, s3_code_prefix)\n",
    "print(f\"S3 Code or Model tar ball uploaded to --- > {code_artifact}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02505842-ea34-43dd-8e50-3d0108e4717e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Model(image_uri=image_uri, model_data=code_artifact, role=role)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004f39f6",
   "metadata": {},
   "source": [
    "## Step4: Create SageMaker endpoint\n",
    "\n",
    "You need to specify the instance to use and endpoint names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0e61cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instance_type = \"ml.g5.48xlarge\"\n",
    "endpoint_name = sagemaker.utils.name_from_base(f\"lmi-model-{model_lineage}-{model_specific_name}\").replace(\".\", \"-\")\n",
    "\n",
    "model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    endpoint_name=endpoint_name,\n",
    "    # container_startup_health_check_timeout=3600\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb63ee65",
   "metadata": {},
   "source": [
    "## Step 5: Test and benchmark the inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef5e1bb-db0e-4b68-b145-42d8df98ff28",
   "metadata": {},
   "source": [
    "### Message API\n",
    "Ref: https://docs.djl.ai/docs/serving/serving/docs/lmi/user_guides/chat_input_output_schema.html#message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a63ccd-ece4-4376-b8d3-1bcf6ea78385",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import time\n",
    "import json\n",
    "import boto3\n",
    "\n",
    "\n",
    "class MessageTokenIterator:\n",
    "    def __init__(self, stream):\n",
    "        self.byte_iterator = iter(stream)\n",
    "        self.buffer = io.BytesIO()\n",
    "        self.read_pos = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        while True:\n",
    "            self.buffer.seek(self.read_pos)\n",
    "            line = self.buffer.readline()\n",
    "\n",
    "            # print(line)\n",
    "            if line and line[-1] == ord(\"\\n\"):\n",
    "                self.read_pos += len(line)\n",
    "                full_line = line[:-1].decode(\"utf-8\")\n",
    "                # print(full_line)\n",
    "                return json.loads(full_line.lstrip(\"data:\").rstrip(\"/n\"))\n",
    "            chunk = next(self.byte_iterator)\n",
    "            self.buffer.seek(0, io.SEEK_END)\n",
    "            self.buffer.write(chunk[\"PayloadPart\"][\"Bytes\"])\n",
    "            \n",
    "prompt = \"tell me a long story.\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "payload = {\n",
    "    \"messages\": messages,\n",
    "    \"max_tokens\": 128,\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_p\": 0.8,\n",
    "    \"stream\": \"true\"\n",
    "}\n",
    "\n",
    "\n",
    "sagemaker_client = boto3.client(\"sagemaker-runtime\")\n",
    "\n",
    "ttft = 0\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "response_stream = sagemaker_client.invoke_endpoint_with_response_stream(\n",
    "    EndpointName=endpoint_name,\n",
    "    Body=json.dumps(payload),\n",
    "    ContentType=\"application/json\",\n",
    "    CustomAttributes='accept_eula=false'\n",
    ")\n",
    "\n",
    "num_tokens = 0\n",
    "for data in MessageTokenIterator(response_stream[\"Body\"]):\n",
    "    token = data[\"choices\"][0][\"delta\"].get(\"content\", \"\")\n",
    "    if token and ttft == 0:\n",
    "        ttft = time.time() - tic\n",
    "    print(token, end=\"\")\n",
    "    num_tokens += 1\n",
    "print(\"TTFT\", ttft)\n",
    "print(\"OTPS\", num_tokens / (time.time() - tic))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fe0d25-fbc7-4337-baf4-d6bf76bcc47e",
   "metadata": {},
   "source": [
    "### Tool calling\n",
    "Ref: [https://docs.djl.ai/master/docs/serving/serving/docs/lmi/user_guides/tool_calling.html](https://docs.djl.ai/master/docs/serving/serving/docs/lmi/user_guides/tool_calling.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad2325f-0f18-42ae-9657-8059d98e5925",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "payload =  {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Hi! How are you doing today?\"\n",
    "        }, \n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"I'm doing well! How can I help you?\"\n",
    "        }, \n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Can you tell me what the temperate will be in Dallas, in fahrenheit?\"\n",
    "        }\n",
    "    ],\n",
    "    \"tools\": [{\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather in a given location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"city\": {\n",
    "                        \"type\":\n",
    "                            \"string\",\n",
    "                        \"description\":\n",
    "                            \"The city to find the weather for, e.g. 'San Francisco'\"\n",
    "                    },\n",
    "                    \"state\": {\n",
    "                        \"type\":\n",
    "                            \"string\",\n",
    "                        \"description\":\n",
    "                            \"the two-letter abbreviation for the state that the city is in, e.g. 'CA' which would mean 'California'\"\n",
    "                    },\n",
    "                    \"unit\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\":\n",
    "                            \"The unit to fetch the temperature in\",\n",
    "                        \"enum\": [\"celsius\", \"fahrenheit\"]\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"city\", \"state\", \"unit\"]\n",
    "            }\n",
    "        }\n",
    "    }],\n",
    "    \"tool_choice\": {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_weather\"\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "response = sagemaker_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    Body=json.dumps(payload),\n",
    "    ContentType=\"application/json\",\n",
    "    CustomAttributes='accept_eula=false'\n",
    ")\n",
    "\n",
    "print(json.loads(response[\"Body\"].read()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cd9042",
   "metadata": {},
   "source": [
    "## Clean up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d674b41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sess.delete_endpoint(endpoint_name)\n",
    "sess.delete_endpoint_config(endpoint_name)\n",
    "model.delete_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
