{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# DeepSeek-R1 671B dynamic quants on SageMaker endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original version of DeepSeek R1 is an FP8 model with 671B parameters, which requires larger GPU instances (such as p5en type) for deployment. \n",
    "\n",
    "Due to resource limitations, in order to deploy on g5, g6 and other instance types, dynamic quantization techniques can be used to reduce resource consumption. Following the technical blog from unsloth: [https://unsloth.ai/blog/deepseekr1-dynamic](https://unsloth.ai/blog/deepseekr1-dynamic), we have implemented the deployment of the DeepSeek-R1 671B dynamic quantization model on SageMaker endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Define some variables\n",
    "\n",
    "This model is inferenced by llama.cpp. To deploy the model on SageMaker endpoint, you need to deploy via BYOC (bring your own container).\n",
    "\n",
    "First you will build and store a llama.cpp endpoint docker image in you ECR private repo (for example `sagemaker_endpoint/llama.cpp`), you need to define the following variables.\n",
    "\n",
    "\n",
    "**⚠️ For China region, you need to make sure the docker image `ghcr.io/ggerganov/llama.cpp:server-cuda` accessible**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_ID = \"unsloth/DeepSeek-R1-GGUF\"\n",
    "QUANT_TYPE = \"DeepSeek-R1-UD-IQ1_S\" # 1.58 bit\n",
    "INSTANCE_TYPE = \"ml.g5.48xlarge\"\n",
    "# INSTANCE_TYPE = \"ml.g6.48xlarge\"\n",
    "\n",
    "# QUANT_TYPE = \"DeepSeek-R1-UD-Q2_K_XL\"  # 2.51 bit, better quality, not support on g5/g6 instance\n",
    "# INSTANCE_TYPE = \"ml.g6e.48xlarge\"\n",
    "\n",
    "REPO_NAMESPACE = \"sagemaker_endpoint/llama.cpp\"\n",
    "REPO_TAG = \"server-cuda\"\n",
    "ACCOUNT = !aws sts get-caller-identity --query Account --output text\n",
    "REGION = !aws configure get region\n",
    "ACCOUNT = ACCOUNT[0]\n",
    "REGION = REGION[0]\n",
    "\n",
    "\n",
    "if REGION.startswith(\"cn\"):\n",
    "    CONTAINER = f\"{ACCOUNT}.dkr.ecr.{REGION}.amazonaws.com.cn/{REPO_NAMESPACE}:{REPO_TAG}\"\n",
    "else:\n",
    "    CONTAINER = f\"{ACCOUNT}.dkr.ecr.{REGION}.amazonaws.com/{REPO_NAMESPACE}:{REPO_TAG}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build the container\n",
    "\n",
    "Endpoint starting codes are in `app/`. The script will build and push to ecr. \n",
    "\n",
    "**The docker only need to be built once**, and after that, when deploying other endpoints, the same docker image can be shared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "cmd = f\"REPO_TAG={REPO_TAG} REPO_NAMESPACE={REPO_NAMESPACE} ACCOUNT={ACCOUNT} REGION={REGION} bash ./build_and_push.sh\"\n",
    "print(\"Runging:\", cmd)\n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Deploy on SageMaker\n",
    "\n",
    "define the model and deploy on SageMaker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (1.36.15)\n",
      "Requirement already satisfied: sagemaker in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (2.239.0)\n",
      "Requirement already satisfied: transformers in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (4.48.2)\n",
      "Requirement already satisfied: huggingface_hub in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (0.28.1)\n",
      "Requirement already satisfied: hf_transfer in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (0.1.9)\n",
      "Requirement already satisfied: botocore<1.37.0,>=1.36.15 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3) (1.36.15)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3) (0.11.2)\n",
      "Requirement already satisfied: attrs<24,>=23.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (23.2.0)\n",
      "Requirement already satisfied: cloudpickle>=2.2.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (2.2.1)\n",
      "Requirement already satisfied: docker in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (7.1.0)\n",
      "Requirement already satisfied: fastapi in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (0.115.6)\n",
      "Requirement already satisfied: google-pasta in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (6.11.0)\n",
      "Requirement already satisfied: jsonschema in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (4.22.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (1.26.4)\n",
      "Requirement already satisfied: omegaconf<=2.3,>=2.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (2.2.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (24.0)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (2.2.2)\n",
      "Requirement already satisfied: pathos in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (0.3.2)\n",
      "Requirement already satisfied: platformdirs in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (4.2.2)\n",
      "Requirement already satisfied: protobuf<6.0,>=3.12 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (4.25.3)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (5.9.8)\n",
      "Requirement already satisfied: pyyaml~=6.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (6.0.1)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (2.32.2)\n",
      "Requirement already satisfied: sagemaker-core<2.0.0,>=1.0.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (1.0.17)\n",
      "Requirement already satisfied: schema in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (0.7.7)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: tblib<4,>=1.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (3.0.0)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (4.66.4)\n",
      "Requirement already satisfied: urllib3<3.0.0,>=1.26.8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (2.2.1)\n",
      "Requirement already satisfied: uvicorn in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (0.32.1)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface_hub) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface_hub) (4.12.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from botocore<1.37.0,>=1.36.15->boto3) (2.9.0.post0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker) (3.19.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from omegaconf<=2.3,>=2.2->sagemaker) (4.9.3)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker-core<2.0.0,>=1.0.17->sagemaker) (2.4.2)\n",
      "Requirement already satisfied: rich<14.0.0,>=13.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker-core<2.0.0,>=1.0.17->sagemaker) (13.7.1)\n",
      "Requirement already satisfied: mock<5.0,>4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker-core<2.0.0,>=1.0.17->sagemaker) (4.0.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema->sagemaker) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema->sagemaker) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema->sagemaker) (0.18.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->sagemaker) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->sagemaker) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->sagemaker) (2024.2.2)\n",
      "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from fastapi->sagemaker) (0.41.3)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from google-pasta->sagemaker) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->sagemaker) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->sagemaker) (2024.1)\n",
      "Requirement already satisfied: ppft>=1.7.6.8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->sagemaker) (1.7.6.8)\n",
      "Requirement already satisfied: dill>=0.3.8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.8)\n",
      "Requirement already satisfied: pox>=0.3.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.4)\n",
      "Requirement already satisfied: multiprocess>=0.70.16 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->sagemaker) (0.70.16)\n",
      "Requirement already satisfied: click>=7.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from uvicorn->sagemaker) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from uvicorn->sagemaker) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker) (2.10.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker) (2.18.0)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from starlette<0.42.0,>=0.40.0->fastapi->sagemaker) (4.6.2.post1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi->sagemaker) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi->sagemaker) (1.2.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U boto3 sagemaker transformers huggingface_hub hf_transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.1 Init SageMaker session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/pydantic/_internal/_fields.py:163: UserWarning: Field name \"json\" shadows an attribute in parent \"Base\"; \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/07/25 06:41:27] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py#1075\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1075</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/07/25 06:41:27]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=18328;file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=452437;file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py#1075\u001b\\\u001b[2m1075\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/07/25 06:41:28] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py#1075\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1075</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/07/25 06:41:28]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=216774;file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=267218;file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py#1075\u001b\\\u001b[2m1075\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/07/25 06:41:29] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py#1075\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1075</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/07/25 06:41:29]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=804660;file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=4543;file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py#1075\u001b\\\u001b[2m1075\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/07/25 06:41:30] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py#1075\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1075</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/07/25 06:41:30]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=559971;file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=762427;file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py#1075\u001b\\\u001b[2m1075\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import json\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "default_bucket = sess.default_bucket()\n",
    "\n",
    "sagemaker_client = boto3.client(\"sagemaker\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Download and upload model file\n",
    "\n",
    "You need to prepare model weights and upload to S3. You can download from [https://huggingface.co/unsloth/DeepSeek-R1-GGUF](https://huggingface.co/unsloth/DeepSeek-R1-GGUF). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local_repo_path: /home/ec2-user/models/unsloth-DeepSeek-R1-GGUF\n"
     ]
    }
   ],
   "source": [
    "model_name = MODEL_ID.replace(\"/\", \"-\").replace(\".\", \"-\")\n",
    "local_repo_path = os.environ['HOME'] + \"/models/\" + model_name\n",
    "\n",
    "s3_model_path = f\"s3://{default_bucket}/models/{model_name}/{QUANT_TYPE}\"\n",
    "\n",
    "%mkdir -p {local_model_path}\n",
    "\n",
    "print(\"local_repo_path:\", local_repo_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the dynamic quant model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model downloaded to /home/ec2-user/models/unsloth-DeepSeek-R1-GGUF/DeepSeek-R1-UD-IQ1_S\n",
      "llama.cpp model DeepSeek-R1-UD-IQ1_S-00001-of-00003.gguf\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"1\"\n",
    "\n",
    "if REGION.startswith(\"cn\"):\n",
    "    # if you are in China region, use a mirror of huggingface\n",
    "    os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'\n",
    "\n",
    "from huggingface_hub import snapshot_download\n",
    "snapshot_download(\n",
    "  repo_id = MODEL_ID,\n",
    "  local_dir = local_repo_path,\n",
    "  allow_patterns = [f\"*{QUANT_TYPE}*\"],\n",
    ")\n",
    "\n",
    "local_model_path = f\"{local_repo_path}/{QUANT_TYPE}\"\n",
    "llamma_cpp_model_name = glob.glob(f\"{local_model_path}/*00001-of-*.gguf\")[0].split(\"/\")[-1]\n",
    "print(\"model downloaded to\", local_model_path)\n",
    "print(\"llama.cpp model\", llamma_cpp_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### upload to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3_model_path: s3://sagemaker-us-west-2-236995464743/models/unsloth-DeepSeek-R1-GGUF/DeepSeek-R1-UD-IQ1_S\n"
     ]
    }
   ],
   "source": [
    "!aws s3 sync {local_model_path} {s3_model_path}\n",
    "print(\"s3_model_path:\", s3_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.3 Prepare llama.cpp start scripts\n",
    "\n",
    "Then you need to a write the llama.cpp starting scripts for endpoint, the container will automatically use the `start.sh` as the entrypont.\n",
    "\n",
    "Please carefully modify the startup script file as needed, such as the model running parameter information. All parameters can be referenced at [https://github.com/ggerganov/llama.cpp/blob/master/examples/server/README.md](https://github.com/ggerganov/llama.cpp/blob/master/examples/server/README.md)\n",
    "\n",
    "Here is a simple script that pulling a model from S3 and starting a llama.cpp server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local_code_path: unsloth-DeepSeek-R1-GGUF-250207-0646\n"
     ]
    }
   ],
   "source": [
    "endpoint_model_name = sagemaker.utils.name_from_base(model_name, short=True)\n",
    "local_code_path = endpoint_model_name\n",
    "s3_code_path = f\"s3://{default_bucket}/endpoint_code/llamacpp_byoc/{endpoint_model_name}.tar.gz\"\n",
    "\n",
    "%mkdir -p {local_code_path}\n",
    "\n",
    "print(\"local_code_path:\", local_code_path)\n",
    "\n",
    "with open(f\"{local_code_path}/start.sh\", \"w\") as f:\n",
    "    f.write(f\"\"\"\n",
    "#!/bin/bash\n",
    "\n",
    "# download model to local\n",
    "s5cmd sync --concurrency 64 \\\n",
    "    \\\"{s3_model_path}/*\\\" /temp/{model_name}/{QUANT_TYPE}\n",
    "\n",
    "/app/llama-server \\\n",
    "    --host 0.0.0.0  --port 8000 \\\n",
    "    -m /temp/{model_name}/{QUANT_TYPE}/{llamma_cpp_model_name} \\\n",
    "    --n-gpu-layers 62 --tensor-split 8,7,8,8,8,8,7,8 \\\n",
    "    -ctk q4_0 \\\n",
    "    --ctx-size 10240 --parallel 2 --batch-size 32 \\\n",
    "    --threads 96 --prio 2 --temp 0.6 --top-p 0.95\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unsloth-DeepSeek-R1-GGUF-250207-0646/\n",
      "unsloth-DeepSeek-R1-GGUF-250207-0646/start.sh\n",
      "upload: ./unsloth-DeepSeek-R1-GGUF-250207-0646.tar.gz to s3://sagemaker-us-west-2-236995464743/endpoint_code/llamacpp_byoc/unsloth-DeepSeek-R1-GGUF-250207-0646.tar.gz\n",
      "s3_code_path: s3://sagemaker-us-west-2-236995464743/endpoint_code/llamacpp_byoc/unsloth-DeepSeek-R1-GGUF-250207-0646.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!rm -f {local_code_path}.tar.gz\n",
    "!tar czvf {local_code_path}.tar.gz {local_code_path}/\n",
    "!aws s3 cp {local_code_path}.tar.gz {s3_code_path}\n",
    "print(\"s3_code_path:\", s3_code_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.3 Deploy endpoint on SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ModelArn': 'arn:aws:sagemaker:us-west-2:236995464743:model/unsloth-DeepSeek-R1-GGUF-250207-0646', 'ResponseMetadata': {'RequestId': '6e7b3ea5-ce41-4ceb-b489-75d32ed0516f', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '6e7b3ea5-ce41-4ceb-b489-75d32ed0516f', 'content-type': 'application/x-amz-json-1.1', 'content-length': '98', 'date': 'Fri, 07 Feb 2025 06:46:41 GMT'}, 'RetryAttempts': 0}}\n",
      "endpoint_model_name: unsloth-DeepSeek-R1-GGUF-250207-0646\n"
     ]
    }
   ],
   "source": [
    "# Step 0. create model\n",
    "\n",
    "# endpoint_model_name already defined in above step\n",
    "\n",
    "create_model_response = sagemaker_client.create_model(\n",
    "    ModelName=endpoint_model_name,\n",
    "    ExecutionRoleArn=role,\n",
    "    PrimaryContainer={\n",
    "        \"Image\": CONTAINER,\n",
    "        \"ModelDataUrl\": s3_code_path\n",
    "    },\n",
    "    \n",
    ")\n",
    "print(create_model_response)\n",
    "print(\"endpoint_model_name:\", endpoint_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EndpointConfigArn': 'arn:aws:sagemaker:us-west-2:236995464743:endpoint-config/unsloth-DeepSeek-R1-GGUF-250207-0646', 'ResponseMetadata': {'RequestId': '15606040-3c5c-4438-acf2-b6f92a582f6d', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '15606040-3c5c-4438-acf2-b6f92a582f6d', 'content-type': 'application/x-amz-json-1.1', 'content-length': '117', 'date': 'Fri, 07 Feb 2025 06:46:48 GMT'}, 'RetryAttempts': 0}}\n",
      "endpoint_config_name: unsloth-DeepSeek-R1-GGUF-250207-0646\n"
     ]
    }
   ],
   "source": [
    "# Step 1. create endpoint config\n",
    "\n",
    "endpoint_config_name = sagemaker.utils.name_from_base(model_name, short=True)\n",
    "\n",
    "endpoint_config_response = sagemaker_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"variant1\",\n",
    "            \"ModelName\": endpoint_model_name,\n",
    "            \"InstanceType\": INSTANCE_TYPE,\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \"ContainerStartupHealthCheckTimeoutInSeconds\": 1000,\n",
    "            # \"EnableSSMAccess\": True,\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "print(endpoint_config_response)\n",
    "print(\"endpoint_config_name:\", endpoint_config_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EndpointArn': 'arn:aws:sagemaker:us-west-2:236995464743:endpoint/unsloth-DeepSeek-R1-GGUF-250207-0646', 'ResponseMetadata': {'RequestId': '203995d4-4d1e-401b-a74f-faef4b96c7cb', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '203995d4-4d1e-401b-a74f-faef4b96c7cb', 'content-type': 'application/x-amz-json-1.1', 'content-length': '104', 'date': 'Fri, 07 Feb 2025 06:46:50 GMT'}, 'RetryAttempts': 0}}\n",
      "endpoint_config_name: unsloth-DeepSeek-R1-GGUF-250207-0646\n",
      "20250207-06:46:50 status: Creating\n",
      "20250207-06:47:51 status: Creating\n",
      "20250207-06:48:51 status: Creating\n",
      "20250207-06:49:51 status: Creating\n",
      "20250207-06:50:51 status: Creating\n",
      "20250207-06:51:51 status: Creating\n",
      "Endpoint created: unsloth-DeepSeek-R1-GGUF-250207-0646\n"
     ]
    }
   ],
   "source": [
    "# Step 2. create endpoint\n",
    "\n",
    "endpoint_name = sagemaker.utils.name_from_base(model_name, short=True)\n",
    "\n",
    "create_endpoint_response = sagemaker_client.create_endpoint(\n",
    "    EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name\n",
    ")\n",
    "print(create_endpoint_response)\n",
    "print(\"endpoint_config_name:\", endpoint_name)\n",
    "while 1:\n",
    "    status = sagemaker_client.describe_endpoint(EndpointName=endpoint_name)[\"EndpointStatus\"]\n",
    "    if status != \"Creating\":\n",
    "        break\n",
    "    print(datetime.now().strftime('%Y%m%d-%H:%M:%S') + \" status: \" + status)\n",
    "    time.sleep(60)\n",
    "print(\"Endpoint created:\", endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test\n",
    "\n",
    "You can invoke your model with SageMaker runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "messages = [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Hi, who are you?\"\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Message api non-stream mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "Hi! I'm DeepSeek-R1, an AI assistant from DeepSeek. I'm glad to interact with you!\n"
     ]
    }
   ],
   "source": [
    "sagemaker_runtime = boto3.client('runtime.sagemaker')\n",
    "\n",
    "payload = {\n",
    "    \"messages\": messages,\n",
    "    \"max_tokens\": 1024,\n",
    "    \"stream\": False\n",
    "}\n",
    "response = sagemaker_runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='application/json',\n",
    "    Body=json.dumps(payload)\n",
    ")\n",
    "\n",
    "print(json.loads(response['Body'].read())[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4.2 Message api stream mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "Hi! I'm DeepSeek-R1, an AI assistant from DeepSeek. I'm at your service.\n"
     ]
    }
   ],
   "source": [
    "payload = {\n",
    "    \"messages\": messages,\n",
    "    \"max_tokens\": 1024,\n",
    "    \"stream\": True\n",
    "}\n",
    "\n",
    "response = sagemaker_runtime.invoke_endpoint_with_response_stream(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='application/json',\n",
    "    Body=json.dumps(payload)\n",
    ")\n",
    "\n",
    "buffer = \"\"\n",
    "for t in response['Body']:\n",
    "    buffer += t[\"PayloadPart\"][\"Bytes\"].decode()\n",
    "    last_idx = 0\n",
    "    for match in re.finditer(r'^data:\\s*(.+?)(\\n\\n)', buffer):\n",
    "        try:\n",
    "            data = json.loads(match.group(1).strip())\n",
    "            last_idx = match.span()[1]\n",
    "            print(data[\"choices\"][0][\"delta\"][\"content\"], end=\"\")\n",
    "        except (json.JSONDecodeError, KeyError, IndexError) as e:\n",
    "            pass\n",
    "    buffer = buffer[last_idx:]\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Completion api non-stream mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "Hi! I'm DeepSeek-R1, an artificial intelligence assistant created by DeepSeek. I'm at your disposal. Feel free to ask me anything, and I'll do my best to provide effective assistance.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "hf_model_id = \"deepseek-ai/DeepSeek-R1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(hf_model_id, trust_remote_code=True)\n",
    "\n",
    "prompt = tokenizer.apply_chat_template(messages, add_generation_prompt=True, tokenize=False)\n",
    "\n",
    "payload = {\n",
    "    \"prompt\": prompt,\n",
    "    \"max_tokens\": 1024,\n",
    "    \"stream\": False\n",
    "}\n",
    "\n",
    "response = sagemaker_runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='application/json',\n",
    "    Body=json.dumps(payload)\n",
    ")\n",
    "\n",
    "print(json.loads(response['Body'].read())[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Completion api stream mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "Hi! I'm DeepSeek-R1, an artificial intelligence assistant created by DeepSeek. I'm at your disposal. Feel free to ask me anything, and I'll do my best to help you.\n"
     ]
    }
   ],
   "source": [
    "payload = {\n",
    "    \"prompt\": prompt,\n",
    "    \"max_tokens\": 1024,\n",
    "    \"stream\": True\n",
    "}\n",
    "\n",
    "response = sagemaker_runtime.invoke_endpoint_with_response_stream(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='application/json',\n",
    "    Body=json.dumps(payload)\n",
    ")\n",
    "\n",
    "buffer = \"\"\n",
    "for t in response['Body']:\n",
    "    buffer += t[\"PayloadPart\"][\"Bytes\"].decode()\n",
    "    last_idx = 0\n",
    "    for match in re.finditer(r'^data:\\s*(.+?)(\\n\\n)', buffer):\n",
    "        try:\n",
    "            data = json.loads(match.group(1).strip())\n",
    "            last_idx = match.end()\n",
    "            # print(data)\n",
    "            print(data[\"choices\"][0][\"text\"], end=\"\")\n",
    "        except (json.JSONDecodeError, KeyError, IndexError) as e:\n",
    "            pass\n",
    "    buffer = buffer[last_idx:]\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Speed test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "嗯，用户让我帮忙写一首七言律诗来介绍上海。首先，我需要考虑用户的需求是什么。可能他们需要一首符合传统格律的诗，用来介绍上海的城市特色。七言律诗通常有八句，每句七个字，平仄对仗都要注意。所以我要确保每句七个字，押韵，对仗工整。\n",
      "\n",
      "接下来，我需要思考上海的特点。上海是国际大都市，有外滩、东方明珠、黄浦江这些地标。还有历史与现代的结合，比如弄堂里的传统和陆家嘴的现代建筑。交通方面，地铁发达，高架桥很多。另外，上海的夜景很美，灯火辉煌，商业繁华，比如南京路步行街。还有上海的历史，比如作为昔日的渔村，后来成为国际港口，有海纳百川的包容精神。\n",
      "\n",
      "然后，我需要把这些元素融入诗中。第一句可能提到上海的繁华，比如“申城锦绣”。然后提到外滩和东方明珠，黄浦江的潮水。接着对比弄堂里的传统和陆家嘴的现代高楼。然后讲交通便利，地铁和高架。再写夜景，灯火如星雨，商业区如南京路。最后总结历史变迁，从渔村到国际都市，体现包容精神。\n",
      "\n",
      "还要注意平仄和对仗。比如“申城锦绣映重霄”对“外滩明珠黄浦潮”，结构上要对应。中间两联要对仗，比如“弄巷犹存风雅韵”对“云楼已矗霁虹桥”，这里“弄巷”和“云楼”都是名词，“风雅韵”和“霁虹桥”也是结构相似。\n",
      "\n",
      "最后两句要总结，提到历史变迁和包容精神。押韵方面，通常律诗押平声韵，一韵到底。检查韵脚是否正确，比如“霄、潮、韵、桥、雨、遥、标”，可能需要调整确保押同一个韵，比如“霄、潮、韵”可能不在同一韵部，可能需要调整韵脚，使其统一。\n",
      "\n",
      "可能用户希望诗既有传统韵味，又能体现现代上海的特点，所以需要平衡古典诗歌形式和现代内容。还要避免生硬堆砌，让诗句流畅自然，有画面感。最后检查字数、对仗、押韵是否符合七律的要求，确保整体结构严谨，意境连贯。\n",
      "</think>\n",
      "\n",
      "好的，我来创作一首介绍上海的七言律诗，并附上赏析：\n",
      "\n",
      "《咏上海》\n",
      "申城锦绣映重霄，外滩明珠黄浦潮。\n",
      "弄巷犹存风雅韵，云楼已矗霁虹桥。\n",
      "千街灯火如星雨，十里商圈胜市朝。\n",
      "昔日渔村今海港，五洲潮涌一襟遥。\n",
      "\n",
      "赏析：\n",
      "这首七言律诗通过生动的意象展现了上海古今交融的都市风貌。首联“申城锦绣映重霄”以璀璨的灯火勾勒出城市天际线的壮丽，“外滩明珠黄浦潮”则巧妙点出外滩与黄浦江的经典地标。颔联“弄巷犹存风雅韵”体现老城厢的历史底蕴，“云楼已矗霁虹桥”展现陆家嘴的现代天际线。颈联描绘南京路等商圈如星雨般绚丽的夜景与繁华的商贸气象。尾联追溯上海从渔村到国际港口的蜕变，以“五洲潮涌一襟遥”收束，彰显其开放包容的胸怀。全诗注重对仗工整，意象丰赡，展现了上海传统与现代交融的独特魅力。\n",
      "==================================================\n",
      "First token latency 0.471 seconds\n",
      "Output speed 9.38 tokens/seconds\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "hf_model_id = \"deepseek-ai/DeepSeek-R1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(hf_model_id, trust_remote_code=True)\n",
    "\n",
    "sagemaker_runtime = boto3.client('runtime.sagemaker')\n",
    "\n",
    "messages = [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"帮我写一首七言律诗介绍上海\"\n",
    "}]\n",
    "\n",
    "payload = {\n",
    "    \"messages\": messages,\n",
    "    \"max_tokens\": 4096,\n",
    "    \"temperature\": 0.0,\n",
    "    \"stream\": True\n",
    "}\n",
    "\n",
    "response = sagemaker_runtime.invoke_endpoint_with_response_stream(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='application/json',\n",
    "    Body=json.dumps(payload)\n",
    ")\n",
    "\n",
    "buffer = \"\"\n",
    "time_start = time.time()\n",
    "first_token_latency = 0\n",
    "output = []\n",
    "for t in response['Body']:\n",
    "    buffer += t[\"PayloadPart\"][\"Bytes\"].decode()\n",
    "    last_idx = 0\n",
    "    for match in re.finditer(r'^data:\\s*(.+?)(\\n\\n)', buffer):\n",
    "        try:\n",
    "            data = json.loads(match.group(1).strip())\n",
    "            last_idx = match.span()[1]\n",
    "            if first_token_latency == 0:\n",
    "                first_token_latency = time.time() - time_start\n",
    "            print(data[\"choices\"][0][\"delta\"][\"content\"], end=\"\")\n",
    "            output.append(data[\"choices\"][0][\"delta\"][\"content\"])\n",
    "        except (json.JSONDecodeError, KeyError, IndexError) as e:\n",
    "            pass\n",
    "    buffer = buffer[last_idx:]\n",
    "\n",
    "\n",
    "total_time = time.time() - time_start\n",
    "\n",
    "num_tokens = tokenizer(\"\".join(output), return_tensors=\"pt\").input_ids.shape[1]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(f\"First token latency {first_token_latency:.3} seconds\")\n",
    "print(f\"Output speed {num_tokens/(total_time-first_token_latency):.3} tokens/seconds\")\n",
    "print(\"=\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
