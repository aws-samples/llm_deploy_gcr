{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "baa086cc-bca5-449a-8298-d8c7d82cd05c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 使用 Bedrock 导入模型 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9319083-13cb-4f61-b85d-bad944b316de",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -U sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5f071c-9d36-47ae-a805-a165edfc0295",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "sagemaker_default_bucket = sess.default_bucket()\n",
    "region = sess.boto_session.region_name\n",
    "print(\"sagemaker_default_bucket:\", sagemaker_default_bucket)\n",
    "print(\"sagemaker_region:\", region)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78f1cf2-f732-443a-b387-813288862dd3",
   "metadata": {},
   "source": [
    "## 1. 微调后的模型 checkpoint 进行 merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5800b919-a6ab-4a8e-bdf5-ca4bfd89c23a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install transformers peft huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97776d0d-d8d2-4cc0-b0de-78b2ad3c1305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adapter_config.json\t   rng_state_2.pth  special_tokens_map.json\n",
      "adapter_model.safetensors  rng_state_3.pth  tokenizer_config.json\n",
      "global_step10\t\t   rng_state_4.pth  tokenizer.json\n",
      "latest\t\t\t   rng_state_5.pth  trainer_state.json\n",
      "README.md\t\t   rng_state_6.pth  training_args.bin\n",
      "rng_state_0.pth\t\t   rng_state_7.pth\n",
      "rng_state_1.pth\t\t   scheduler.pt\n"
     ]
    }
   ],
   "source": [
    "# 先看一下取训练过程中保存的一个checkpoint，用于与原始模型进行merge\n",
    "!ls ./deepseek_model_finetuned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc966818-5646-4d41-bea3-1fb918f68a70",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.1 merge 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab5fba4-c904-4b15-aff2-b4a1b6c35c93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile merge_model.py\n",
    "import torch\n",
    "from transformers import AutoConfig, AutoTokenizer, AutoModelForCausalLM, TextIteratorStreamer, GenerationConfig\n",
    "from peft import PeftModel\n",
    "\n",
    "def apply_lora(model_name_or_path, output_path, lora_path):\n",
    "    print(f\"Loading the base model from {model_name_or_path}\")\n",
    "    base = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name_or_path, torch_dtype=torch.float16, low_cpu_mem_usage=True\n",
    "    )\n",
    "    base_tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "\n",
    "    print(f\"Loading the LoRA adapter from {lora_path}\")\n",
    "\n",
    "    lora_model = PeftModel.from_pretrained(\n",
    "        base,\n",
    "        lora_path,\n",
    "        torch_dtype=torch.float16,\n",
    "    )\n",
    "\n",
    "    print(\"Applying the LoRA\")\n",
    "    model = lora_model.merge_and_unload()\n",
    "\n",
    "    print(f\"Saving the target model to {output_path}\")\n",
    "    model.save_pretrained(output_path)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    apply_lora(\"deepseek-ai/deepseek-coder-6.7b-base\", \"deepseek_finetuned_merged\", \"deepseek_model_finetuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b658557-d82f-4fa8-b89e-7f3555fcb06d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python merge_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f9fa15-a947-4da8-b383-1e810286f1ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#可以看到合并后的模型文件输出没有 tokenizer 相关的配置\n",
    "!ls deepseek_finetuned_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc661514",
   "metadata": {},
   "source": [
    "### 1.2 修改 config.json\n",
    "\n",
    "- 将 \"max_position_embeddings\": 16384 修改成 \"max_position_embeddings\": 8192,\n",
    "\n",
    "\n",
    "![config_change](./images/max_pos_change.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886677a7-ee9f-4b8b-b654-702229b6027c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sed -i 's/\\\"max_position_embeddings\\\"\\: 16384/\\\"max_position_embeddings\\\"\\: 8192/g' deepseek_finetuned_merged/config.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4bfbec-ea28-4a20-b330-f7ca7c29f393",
   "metadata": {},
   "source": [
    "## 2. 将训练过程中的 tokenizer 相关文件拷贝到合并的模型文件路径下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a19798-642f-4fd1-9978-039cbfd35ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp ./deepseek_model_finetuned/special_tokens_map.json ./deepseek_model_finetuned/tokenizer_config.json ./deepseek_model_finetuned/tokenizer.json ./deepseek_finetuned_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92696f0-5c72-4611-830c-9e6b48154215",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ls ./deepseek_finetuned_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfe0160-6aa0-4466-a9f4-69c6d2679c0d",
   "metadata": {},
   "source": [
    "## 3. 将 merge 后的完整模型文件上传 S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f75882c-93e3-4df1-a8ba-f612df737eaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!aws s3 cp ./deepseek_finetuned_merged/ s3://{sagemaker_default_bucket}/finetuned-model/deepseek_base6.7B_lora_merged --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66665579-4d66-4f2d-bf88-2729b8e00415",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 可以看到模型文件都已经上传\n",
    "!aws s3 ls s3://{sagemaker_default_bucket}/finetuned-model/deepseek_base6.7B_lora_merged/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecc7d95-b457-464f-b555-b018be9f9628",
   "metadata": {},
   "source": [
    "## 4. 通过 console 导入到 Bedrock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9afa09",
   "metadata": {},
   "source": [
    "<!-- ![config_change](./images/import_to_bedrock.png) -->\n",
    "<img src=./images/import_to_bedrock.png width=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240c39ef-c588-403b-a317-48d9e2550212",
   "metadata": {},
   "source": [
    "## 5. 测试推理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b4dd12",
   "metadata": {},
   "source": [
    "### 5.1 Console playground 推理\n",
    "\n",
    "<img src=./images/test_model.jpeg width=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de327f0-29b4-40ab-92f6-7c0d73003492",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 5.2 Python SDK 调用测试\n",
    "- 注意将 model_arn 的值改成部署自己部署在bedrock的 model arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3485e11a-2c75-450b-8175-6d298e0e71c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "# 注意将 model_arn 的值改成部署自己部署在bedrock的 model arn\n",
    "model_arn = \"Your model arn\"\n",
    "\n",
    "client = boto3.client(service_name=\"bedrock-runtime\")\n",
    "body = json.dumps({\n",
    "    'prompt': '#write a quick sort algorithm',\n",
    "    'max_tokens': 512,\n",
    "    'top_k': 200,\n",
    "    'top_p': 0.9,\n",
    "    'stop': [],\n",
    "    'temperature': 0.5\n",
    "})\n",
    "\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'\n",
    "\n",
    "response = client.invoke_model(body=body, modelId=model_arn, accept=accept, contentType=contentType)\n",
    "\n",
    "response_body = json.loads(response.get('body').read())\n",
    "\n",
    "# text\n",
    "print(response_body.get('outputs')[0][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8ff3a3-89d8-41d9-804e-37ebe1100630",
   "metadata": {},
   "source": [
    "## Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c6b8ec-7e05-4423-84bf-2ddfa51bc90e",
   "metadata": {},
   "source": [
    " - https://aws.amazon.com/cn/blogs/aws/import-custom-models-in-amazon-bedrock-preview/?nc1=h_ls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fc_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
